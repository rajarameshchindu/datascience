{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajarameshchindu/datascience/blob/master/Write_Better_Python_Functions_Using_Type_Dispatch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1NYRKfUB7HR"
      },
      "source": [
        "https://www.analyticsvidhya.com/blog/2021/04/write-better-python-functions-using-type-dispatch/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+AnalyticsVidhya+%28Analytics+Vidhya%29"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgplosvVBnlo"
      },
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "# Set Torch device to GPU if CUDA supported GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Function to convert image to Torch tensor\n",
        "def Tensor(inp):\n",
        "    \n",
        "    # Read image from disk using PIL Image\n",
        "    img = PILImage.open(inp).convert('RGB')\n",
        "    \n",
        "    # Convert the image to numpy ndarray\n",
        "    imgArr = np.asarray(img, np.uint8)\n",
        "    \n",
        "    # Rearrange the shape of the array so that it is pytorch compatible\n",
        "    imgArr = imgArr.transpose(2, 0, 1)\n",
        "    \n",
        "    # Convert Numpy array to Torch Tensor and move it to device\n",
        "    return torch.from_numpy(imgArr).to(device)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7jmr2QdBoW2",
        "outputId": "8d95d11e-6345-4d0f-b67d-8fddef203f26"
      },
      "source": [
        "# Download a sample image to disk\n",
        "import urllib.request \n",
        "\n",
        "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Python-logo-notext.svg/200px-Python-logo-notext.svg.png\"\n",
        "filename = \"sample.png\"\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sample.png', <http.client.HTTPMessage at 0x7f3841d6e490>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li-gZOtXB4sE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ddefbf-ede5-47f0-ae21-15a171c882a3"
      },
      "source": [
        "# Pass the sample image through our function\n",
        "imgTensor = Tensor(filename)\n",
        "\n",
        "# Check whether the output of the function is a Tensor\n",
        "assert isinstance(imgTensor, torch.Tensor), \"Not a Tensor\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsNwfr76DBBO"
      },
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image as PILImage\n",
        "from pathlib import Path, PurePath\n",
        "\n",
        "# Set Torch device to GPU if CUDA supported GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# Function to convert image to Torch tensor\n",
        "def from_multiInput_toTensor(inp):\n",
        "    \n",
        "    # Input type - str/ Path, then read from disk & convert to array\n",
        "    if isinstance(inp, (str, PurePath)):\n",
        "        try: \n",
        "            image = PILImage.open(inp).convert('RGB')\n",
        "            imageArray = np.asarray(image.copy(), np.uint8)\n",
        "        except Exception as error:\n",
        "            raise error\n",
        "            \n",
        "    # Input type - PIL Image, then we convert it to array      \n",
        "    elif isinstance(inp, PILImage.Image):\n",
        "        imageArray = np.asarray(inp, np.uint8)\n",
        "        \n",
        "    # Input type - ndarray, then assign it to imageArray variable  \n",
        "    elif isinstance(inp, np.ndarray):\n",
        "        imageArray = inp\n",
        "        \n",
        "    # Raise TypeError with input type is not supported\n",
        "    else: \n",
        "        raise TypeError(\"Input must be of Type - String or Path or PIL Image or Numpy array\")\n",
        "        \n",
        "    # Rearrange shape of the array so that it is pytorch compatible\n",
        "    if imageArray.ndim == 3: imageArray = imageArray.transpose(2, 0, 1)\n",
        "        \n",
        "    # Convert Numpy array to Torch Tensor and move it to device\n",
        "    return torch.from_numpy(imageArray).to(device)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtfGFR_wDBl5"
      },
      "source": [
        "# Test if two torch tensors are same or not\n",
        "def is_same_tensor(tensor1, tensor2):\n",
        "    assert torch.eq(tensor1, tensor2).all(), \"The Tensors are not equal!\"\n",
        "    return True"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztciL8HZDb16",
        "outputId": "e135870b-0dbe-4795-e143-d793101d2475"
      },
      "source": [
        "# Verify that the output of two versions are same or not\n",
        "is_same_tensor(Tensor(filename), from_multiInput_toTensor(filename))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNhIZ9xzDf0A",
        "outputId": "2ddd9e51-4e40-440b-e8ad-2143e264f121"
      },
      "source": [
        "# Check the support for Path\n",
        "path = Path(Path.cwd(), filename).resolve()\n",
        "is_same_tensor(Tensor(filename), from_multiInput_toTensor(path))\n",
        "\n",
        "# Check the support for PIL Image\n",
        "image = PILImage.open(filename).convert('RGB')\n",
        "is_same_tensor(Tensor(filename), from_multiInput_toTensor(image))\n",
        "\n",
        "# Check the support for Ndarray\n",
        "imageArray = np.asarray(image, np.uint8)\n",
        "is_same_tensor(Tensor(filename), from_multiInput_toTensor(imageArray))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A58M1Gh7DlNt",
        "outputId": "2fb464ad-4e47-46fd-995f-7ea00e2111c6"
      },
      "source": [
        "# Validate whether an error is thrown when user passes wrong file\n",
        "from_multiInput_toTensor('/content/sample.png')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "ZqaLLCTAED3J",
        "outputId": "0a43a257-0dc6-4d09-bc16-41f5f9ae4b90"
      },
      "source": [
        "# Validate whether an error is thrown when user passes wrong file\n",
        "from_multiInput_toTensor('test.png')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d7f024b1580d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Validate whether an error is thrown when user passes wrong file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfrom_multiInput_toTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-bb7f1dd75c4a>\u001b[0m in \u001b[0;36mfrom_multiInput_toTensor\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mimageArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Input type - PIL Image, then we convert it to array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-bb7f1dd75c4a>\u001b[0m in \u001b[0;36mfrom_multiInput_toTensor\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPurePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPILImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mimageArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "-TKxfSb-EX8f",
        "outputId": "5b17c9b7-e693-402f-daf1-2a99d810044a"
      },
      "source": [
        "# Validate whether an error is thrown when input type is list\n",
        "from_multiInput_toTensor([filename])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5db47c7555d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Validate whether an error is thrown when input type is list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfrom_multiInput_toTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-bb7f1dd75c4a>\u001b[0m in \u001b[0;36mfrom_multiInput_toTensor\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Raise TypeError with input type is not supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input must be of Type - String or Path or PIL Image or Numpy array\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Rearrange shape of the array so that it is pytorch compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Input must be of Type - String or Path or PIL Image or Numpy array"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7W7Bg_kEcAc"
      },
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image as PILImage\n",
        "from pathlib import Path, PurePath\n",
        "\n",
        "# Change numpy array to torch tensor\n",
        "def numpy_ToImageTensor(imageArray):\n",
        "    \n",
        "    # if not type - ndarray then raise error\n",
        "    if not isinstance(imageArray, np.ndarray):\n",
        "        raise TypeError(\"Input must be of Type - Numpy array\")\n",
        "    \n",
        "    # Set Torch device to GPU if CUDA supported GPU is available\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Transpose the numpy array before converting it to Tensor\n",
        "    if imageArray.ndim == 3: imageArray = imageArray.transpose(2, 0, 1)\n",
        "    return torch.from_numpy(imageArray).to(device)\n",
        "\n",
        "# Change image to torch tensor\n",
        "def pil_ToImageTensor(image):\n",
        "    \n",
        "    # if not type - PIL Image then raise error\n",
        "    if not isinstance(image, PILImage.Image):\n",
        "        raise TypeError(\"Input must be of Type - PIL image\")\n",
        "        \n",
        "    # Convert the image to numpy \n",
        "    imageArray = np.array(image)\n",
        "    \n",
        "    # Return output of numpy_ToImageTensor function\n",
        "    return numpy_ToImageTensor(imageArray)\n",
        "\n",
        "# Change image file to torch tensor\n",
        "def file_ToImageTensor(file):\n",
        "    \n",
        "    # if not input - string or Path then raise error\n",
        "    if not isinstance(file, (str, PurePath)):\n",
        "        raise TypeError(\"Input must be of Type - String or Path\")\n",
        "        \n",
        "    # Read the image from disk and raise error (if any)\n",
        "    try: \n",
        "        image = PILImage.open(file).convert('RGB')\n",
        "    except Exception as error:\n",
        "        raise error\n",
        "    \n",
        "    # Return output of pil_ToImageTensor function\n",
        "    return pil_ToImageTensor(image)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1BrK30aErTE",
        "outputId": "2da2ec09-717c-4c36-ccd3-9d7bf97f2c89"
      },
      "source": [
        "is_same_tensor(from_multiInput_toTensor(filename), file_ToImageTensor(filename))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "afelNwnDIvM8",
        "outputId": "921ac9f3-aff2-498a-bcf3-d83e46af4169"
      },
      "source": [
        "from fastcore.all import"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-039d112d2a1b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    from fastcore.all import\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGn7m3YVI187"
      },
      "source": [
        "from typing import List"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "8bGPaD1GI8Ju",
        "outputId": "26c4350a-7df7-479d-a8f1-b678e8e2c621"
      },
      "source": [
        "# Function to multiply two ndarrays\n",
        "@typedispatch\n",
        "def multiple(x:np.ndarray, y:np.ndarray ): \n",
        "    return x * y"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-3ac0d38bc003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Function to multiply two ndarrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtypedispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmultiple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'typedispatch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "sR3mABrGGZOv",
        "outputId": "bac2cd33-4ab9-4637-8e03-62626a6242e9"
      },
      "source": [
        "from fastcore.all import *\n",
        "from typing import List\n",
        "\n",
        "# Function to multiply two ndarrays\n",
        "@typedispatch\n",
        "def multiple(x:np.ndarray, y:np.ndarray ): \n",
        "    return x * y\n",
        "\n",
        "# Function to multiply a List by an integer\n",
        "@typedispatch\n",
        "def multiple(lst:List, x:int): \n",
        "    return [ x*val for val in lst]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c59437af53fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Function to multiply two ndarrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtypedispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastcore'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "2I7llQcQGgeR",
        "outputId": "4ecb9b21-a1cf-4352-ac4e-396bc11790ad"
      },
      "source": [
        "x = np.arange(1,3)\n",
        "print(f'x is {x}')\n",
        "\n",
        "y = np.array(10)\n",
        "print(f'y is {y}')\n",
        "\n",
        "print(f'Result of multiplying two numpy arrays: { multiple(x, y)}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x is [1 2]\n",
            "y is 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-33eeca4f6d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'y is {y}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Result of multiplying two numpy arrays: { multiple(x, y)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'multiple' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "a_69CRwXGyqS",
        "outputId": "882d9279-9b4e-428c-ad3b-108a156fa803"
      },
      "source": [
        "x = [1, 2]\n",
        "print(f'x is {x}')\n",
        "\n",
        "y = 10\n",
        "print(f'y is {y}')\n",
        "\n",
        "print(f'Result of multiplying a List of integers by an integer: {multiple(x, y)}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x is [1, 2]\n",
            "y is 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-13e3abfe2ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'y is {y}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Result of multiplying a List of integers by an integer: {multiple(x, y)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'multiple' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "fNDo37uPJeLA",
        "outputId": "2a3965d5-df93-4136-9431-7862fab01508"
      },
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image as PILImage\n",
        "from pathlib import Path, PurePath\n",
        "from fastcore.all import *\n",
        "\n",
        "\n",
        "@typedispatch\n",
        "def to_imageTensor(arr: np.ndarray) -> torch.Tensor:\n",
        "    \"\"\"Change ndarray to torch tensor.\n",
        "    \n",
        "    The ndarray would be of the shape (Height, Width, # of Channels)\n",
        "    but pytorch tensor expects the shape as \n",
        "    (# of Channels, Height, Width) before putting \n",
        "    the Tensor on GPU if it's available.\n",
        "    \n",
        "    Args:\n",
        "        arr[ndarray]: Ndarray which needs to be \n",
        "        converted to torch tensor\n",
        "    \n",
        "    Returns:\n",
        "        Torch tensor on GPU (if it's available)   \n",
        "    \"\"\"\n",
        "    \n",
        "    # Set Torch device to GPU if CUDA supported GPU is available\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    # Transpose the array before converting to tensor\n",
        "    imgArr = arr.transpose(2, 0, 1) if arr.ndim == 3 else arr\n",
        "    return torch.Tensor(imgArr).to(device)\n",
        "\n",
        "\n",
        "@typedispatch\n",
        "def to_imageTensor(image: PILImage.Image) -> torch.Tensor:\n",
        "    \"\"\"Change image to torch tensor.\n",
        "    \n",
        "    The PIL image cast as numpy array with dtype as uint8,\n",
        "    and then passed to to_imageTensor(arr: np.ndarray) function\n",
        "    for converting numpy array to torch tensor.\n",
        "    \n",
        "    Args:\n",
        "        image[PILImage.Image]: PIL Image which \n",
        "        needs to be converted to torch tensor\n",
        "    \n",
        "    Returns:\n",
        "        Torch tensor on GPU (if it's available)   \n",
        "    \n",
        "    \"\"\"\n",
        "    return to_imageTensor(np.asarray(image, np.uint8))\n",
        "\n",
        "\n",
        "@typedispatch\n",
        "def to_imageTensor(file: (str, PurePath)) -> torch.Tensor:\n",
        "    \"\"\"Change image file to torch tensor.\n",
        "    \n",
        "    Read the image from disk as 3 channels (RGB) using PIL, \n",
        "    and passed on to to_imageTensor(image: PILImage.Image)\n",
        "    function for converting Image to torch tensor.\n",
        "    \n",
        "    Args:\n",
        "        file[str, PurePath]: Image file name which needs to\n",
        "        be converted to torch tensor\n",
        "    \n",
        "    Returns:\n",
        "        Torch tensor on GPU (if it's available)\n",
        "    \n",
        "    Raises:\n",
        "        Any error thrown while reading the image file,\n",
        "        Mostly FileNotFoundError will be raised.\n",
        "    \n",
        "    \"\"\"\n",
        "    try: \n",
        "        img = PILImage.open(file).convert('RGB')\n",
        "    except Exception as error:\n",
        "        raise error\n",
        "    return to_imageTensor(img)\n",
        "\n",
        "\n",
        "@typedispatch\n",
        "def to_imageTensor(x:object) -> None:\n",
        "    \"\"\"For unsupported data types, raise TypeError. \"\"\"\n",
        "    raise TypeError('Input must be of Type - String or Path or PIL Image or Numpy array')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-e1e6eed208be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mPILImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPurePath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastcore'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "-huX99-WJnlA",
        "outputId": "5456ca25-afbc-4e85-8d9c-d2f39fe049d1"
      },
      "source": [
        "import inspect\n",
        "inspect.signature(to_imageTensor[np.ndarray])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-84e68d5b0ad3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_imageTensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'to_imageTensor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "9IzYMUFUKaJ9",
        "outputId": "0818b6c6-5d9c-4b73-f67d-0e9aaac63786"
      },
      "source": [
        "print(to_imageTensor[np.ndarray].__doc__)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-23038d835c0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_imageTensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'to_imageTensor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "3pgotD4QKkMO",
        "outputId": "92d4bc45-e14c-4d3e-e666-ddff9f5569a1"
      },
      "source": [
        "is_same_tensor(file_ToImageTensor(filename), to_imageTensor(filename))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-b05379f5870f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mis_same_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ToImageTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_imageTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'to_imageTensor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "WwcWMfwvKs78",
        "outputId": "0fac860b-d163-4b02-ceb0-b389395e8e52"
      },
      "source": [
        "to_imageTensor([filename])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-670871404220>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mto_imageTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'to_imageTensor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xNyrDl7LFsN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}